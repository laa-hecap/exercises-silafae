// For format details, see https://aka.ms/devcontainer.json.
{
  "name": "Verba and Ollama Automated Environment",
  "image": "mcr.microsoft.com/devcontainers/python:3.10-bullseye",

  // This "feature" automatically installs and configures the Ollama service.
  "features": {
    "ghcr.io/prulloac/devcontainer-features/ollama:1": {}
  },

  // This single command runs after the container is created to perform all setup steps.
  "postCreateCommand": "git clone https://github.com/weaviate/Verba.git && echo -e 'OLLAMA_URL=http://localhost:11434\nOLLAMA_MODEL=llama3\nOLLAMA_EMBED_MODEL=snowflake-arctic-embed' > Verba/.env && cd Verba && pip install -r requirements.txt && (for model in mistral llama3 gemma2:2b snowflake-arctic-embed; do ollama pull $model; done)",

  // Specifies the minimum resources required for this Codespace to run smoothly.
  "hostRequirements": {
    "memory": "16gb"
  },

  // Forward the necessary ports and give them descriptive labels.
  "forwardPorts": [8501, 8000],
  "portsAttributes": {
    "8501": {
      "label": "Verba Frontend (UI)"
    },
    "8000": {
      "label": "Verba Backend (API)"
    }
  }
}
